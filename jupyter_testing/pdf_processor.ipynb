{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDF Processing with PDFExtractor\n",
    "\n",
    "This notebook demonstrates how to use the PDFExtractor class to extract text and images from PDF files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import base64\n",
    "import json\n",
    "\n",
    "# Add project root to path to import the Psycore modules\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "# Import Psycore modules\n",
    "from src.data.common_types import AttachmentTypes\n",
    "from src.data.attachments import Attachment, FailedExtraction\n",
    "from src.data.pdf_extractor import PDFExtractor\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(\"pdf_processor\")\n",
    "\n",
    "# Set up output directory\n",
    "OUTPUT_DIR = os.path.join(os.getcwd(), \"processed_pdfs\")\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "print(\"Setup completed. Output directory is:\", OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. List Available PDF Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all PDF files in the testing directory\n",
    "PDF_DIR = os.path.join(os.getcwd(), \"testing\")\n",
    "pdf_files = [f for f in os.listdir(PDF_DIR) if f.endswith(\".pdf\")]\n",
    "\n",
    "if not pdf_files:\n",
    "    print(\"No PDF files found in directory:\", PDF_DIR)\n",
    "else:\n",
    "    print(f\"Found {len(pdf_files)} PDF files:\")\n",
    "    for i, pdf_file in enumerate(pdf_files):\n",
    "        file_path = os.path.join(PDF_DIR, pdf_file)\n",
    "        file_size = os.path.getsize(file_path) / (1024 * 1024)  # Convert to MB\n",
    "        print(f\"{i+1}. {pdf_file} ({file_size:.2f} MB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define PDF Processing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_pdf(pdf_path, output_dir=None):\n",
    "    \"\"\"\n",
    "    Process a PDF file using the PDFExtractor and save results.\n",
    "    \n",
    "    Args:\n",
    "        pdf_path: Path to the PDF file\n",
    "        output_dir: Directory to save processed content (optional)\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with processing results\n",
    "    \"\"\"\n",
    "    result = {\n",
    "        \"filename\": os.path.basename(pdf_path),\n",
    "        \"success\": False,\n",
    "        \"text_extracted\": False,\n",
    "        \"image_count\": 0,\n",
    "        \"error\": None,\n",
    "        \"output_dir\": None\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Create output directory if specified\n",
    "        pdf_basename = os.path.basename(pdf_path).replace(\".\", \"_\")\n",
    "        \n",
    "        if output_dir:\n",
    "            result_dir = os.path.join(output_dir, pdf_basename)\n",
    "            os.makedirs(result_dir, exist_ok=True)\n",
    "            result[\"output_dir\"] = result_dir\n",
    "        \n",
    "        # Create attachment and process it\n",
    "        attachment = Attachment(AttachmentTypes.FILE, pdf_path, True)\n",
    "        attachment.extract()\n",
    "        \n",
    "        # Get extracted images\n",
    "        extracted_images = attachment.pop_extra_attachments()\n",
    "        result[\"image_count\"] = len(extracted_images)\n",
    "        \n",
    "        # Get extracted text\n",
    "        extracted_text = attachment.attachment_data\n",
    "        result[\"text_extracted\"] = len(extracted_text) > 0\n",
    "        \n",
    "        # Save results if output directory is specified\n",
    "        if output_dir:\n",
    "            # Save text content\n",
    "            if result[\"text_extracted\"]:\n",
    "                text_path = os.path.join(result_dir, \"extracted_text.txt\")\n",
    "                with open(text_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                    f.write(extracted_text)\n",
    "            \n",
    "            # Save extracted images\n",
    "            images_dir = os.path.join(result_dir, \"images\")\n",
    "            os.makedirs(images_dir, exist_ok=True)\n",
    "            \n",
    "            for i, img in enumerate(extracted_images):\n",
    "                try:\n",
    "                    # Convert base64 to image\n",
    "                    img_data = img.attachment_data\n",
    "                    img_bytes = base64.b64decode(img_data)\n",
    "                    \n",
    "                    # Save the image\n",
    "                    img_path = os.path.join(images_dir, f\"image_{i+1}.jpg\")\n",
    "                    with open(img_path, \"wb\") as f:\n",
    "                        f.write(img_bytes)\n",
    "                except Exception as e:\n",
    "                    logger.warning(f\"Failed to save image {i+1}: {str(e)}\")\n",
    "            \n",
    "            # Save metadata\n",
    "            metadata = {\n",
    "                \"filename\": os.path.basename(pdf_path),\n",
    "                \"text_length\": len(extracted_text),\n",
    "                \"image_count\": len(extracted_images),\n",
    "                \"processed_at\": str(datetime.now())\n",
    "            }\n",
    "            \n",
    "            metadata_path = os.path.join(result_dir, \"metadata.json\")\n",
    "            with open(metadata_path, \"w\") as f:\n",
    "                json.dump(metadata, f, indent=2)\n",
    "        \n",
    "        result[\"success\"] = True\n",
    "        \n",
    "    except FailedExtraction as e:\n",
    "        result[\"success\"] = False\n",
    "        result[\"error\"] = str(e)\n",
    "        logger.error(f\"Failed extraction for {pdf_path}: {str(e)}\")\n",
    "    except Exception as e:\n",
    "        result[\"success\"] = False\n",
    "        result[\"error\"] = str(e)\n",
    "        logger.error(f\"Error processing {pdf_path}: {str(e)}\")\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Process a Single PDF File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Select the first PDF file for processing\n",
    "if pdf_files:\n",
    "    selected_pdf = pdf_files[0]\n",
    "    pdf_path = os.path.join(PDF_DIR, selected_pdf)\n",
    "    \n",
    "    print(f\"Processing PDF: {selected_pdf}\")\n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    # Process the PDF\n",
    "    result = process_pdf(pdf_path, OUTPUT_DIR)\n",
    "    \n",
    "    # Calculate processing time\n",
    "    processing_time = datetime.now() - start_time\n",
    "    \n",
    "    # Display results\n",
    "    print(f\"\\nProcessing completed in {processing_time.total_seconds():.2f} seconds\")\n",
    "    print(f\"Success: {result['success']}\")\n",
    "    \n",
    "    if result['success']:\n",
    "        print(f\"Extracted text: {'Yes' if result['text_extracted'] else 'No'}\")\n",
    "        print(f\"Images extracted: {result['image_count']}\")\n",
    "        print(f\"Results saved to: {result['output_dir']}\")\n",
    "    else:\n",
    "        print(f\"Error: {result['error']}\")\n",
    "else:\n",
    "    print(\"No PDF files available for processing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Display PDF Text Preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a preview of the extracted text\n",
    "if 'result' in locals() and result['success'] and result['text_extracted']:\n",
    "    text_path = os.path.join(result['output_dir'], \"extracted_text.txt\")\n",
    "    \n",
    "    if os.path.exists(text_path):\n",
    "        with open(text_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            text_content = f.read()\n",
    "        \n",
    "        print(f\"Text Preview ({len(text_content)} characters):\")\n",
    "        print(\"=\"*80)\n",
    "        print(text_content[:1000] + \"...\" if len(text_content) > 1000 else text_content)\n",
    "        print(\"=\"*80)\n",
    "    else:\n",
    "        print(\"Extracted text file not found.\")\n",
    "elif 'result' in locals():\n",
    "    print(\"No text was extracted from the PDF.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Display Extracted Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the extracted images\n",
    "if 'result' in locals() and result['success'] and result['image_count'] > 0:\n",
    "    from IPython.display import Image, display\n",
    "    \n",
    "    images_dir = os.path.join(result['output_dir'], \"images\")\n",
    "    image_files = [f for f in os.listdir(images_dir) if f.endswith(\".jpg\")]\n",
    "    \n",
    "    print(f\"Found {len(image_files)} extracted images:\")\n",
    "    \n",
    "    # Show first 5 images\n",
    "    for i, img_file in enumerate(image_files[:5]):\n",
    "        print(f\"\\nImage {i+1}/{len(image_files)}:\")\n",
    "        img_path = os.path.join(images_dir, img_file)\n",
    "        display(Image(filename=img_path))\n",
    "    \n",
    "    if len(image_files) > 5:\n",
    "        print(f\"\\n... {len(image_files) - 5} more images not displayed\")\n",
    "elif 'result' in locals() and result['success']:\n",
    "    print(\"No images were extracted from the PDF.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Process All PDF Files in Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if tqdm is installed, if not install it\n",
    "try:\n",
    "    from tqdm.notebook import tqdm\n",
    "except ImportError:\n",
    "    !pip install tqdm\n",
    "    from tqdm.notebook import tqdm\n",
    "\n",
    "# Process all PDF files in batch\n",
    "if pdf_files:\n",
    "    # Create a timestamp for this batch run\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    batch_dir = os.path.join(OUTPUT_DIR, f\"batch_{timestamp}\")\n",
    "    os.makedirs(batch_dir, exist_ok=True)\n",
    "    \n",
    "    print(f\"Processing {len(pdf_files)} PDF files in batch...\")\n",
    "    \n",
    "    # Process each PDF file\n",
    "    results = []\n",
    "    for pdf_file in tqdm(pdf_files, desc=\"Processing PDFs\"):\n",
    "        pdf_path = os.path.join(PDF_DIR, pdf_file)\n",
    "        result = process_pdf(pdf_path, batch_dir)\n",
    "        results.append(result)\n",
    "    \n",
    "    # Summarize results\n",
    "    successful = sum(1 for r in results if r[\"success\"])\n",
    "    failed = len(results) - successful\n",
    "    total_images = sum(r[\"image_count\"] for r in results if r[\"success\"])\n",
    "    \n",
    "    print(f\"\\nBatch processing complete!\")\n",
    "    print(f\"- Successfully processed: {successful}/{len(results)} PDFs\")\n",
    "    print(f\"- Failed: {failed}/{len(results)} PDFs\")\n",
    "    print(f\"- Total images extracted: {total_images}\")\n",
    "    print(f\"- Results saved to: {batch_dir}\")\n",
    "    \n",
    "    # Save summary report\n",
    "    summary = {\n",
    "        \"timestamp\": timestamp,\n",
    "        \"total_files\": len(results),\n",
    "        \"successful\": successful,\n",
    "        \"failed\": failed,\n",
    "        \"total_images\": total_images,\n",
    "        \"pdf_files\": [{\n",
    "            \"filename\": r[\"filename\"],\n",
    "            \"success\": r[\"success\"],\n",
    "            \"text_extracted\": r[\"text_extracted\"],\n",
    "            \"image_count\": r[\"image_count\"],\n",
    "            \"error\": r[\"error\"]\n",
    "        } for r in results]\n",
    "    }\n",
    "    \n",
    "    summary_path = os.path.join(batch_dir, \"summary.json\")\n",
    "    with open(summary_path, \"w\") as f:\n",
    "        json.dump(summary, f, indent=2, default=str)\n",
    "else:\n",
    "    print(\"No PDF files available for batch processing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Analyze Image Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the distribution of extracted images\n",
    "if 'results' in locals() and results:\n",
    "    try:\n",
    "        import matplotlib.pyplot as plt\n",
    "    except ImportError:\n",
    "        !pip install matplotlib\n",
    "        import matplotlib.pyplot as plt\n",
    "    \n",
    "    # Collect image counts\n",
    "    successful_pdfs = [r for r in results if r[\"success\"]]\n",
    "    pdf_names = [r[\"filename\"].split(\".pdf\")[0] for r in successful_pdfs]\n",
    "    image_counts = [r[\"image_count\"] for r in successful_pdfs]\n",
    "    \n",
    "    # Display chart\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.bar(pdf_names, image_counts)\n",
    "    plt.title(\"Images Extracted per PDF\")\n",
    "    plt.xlabel(\"PDF File\")\n",
    "    plt.ylabel(\"Number of Images\")\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Add value labels\n",
    "    for i, v in enumerate(image_counts):\n",
    "        plt.text(i, v + 0.5, str(v), ha='center')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    # Calculate statistics\n",
    "    if image_counts:\n",
    "        avg_images = sum(image_counts) / len(image_counts)\n",
    "        max_images = max(image_counts)\n",
    "        max_pdf = pdf_names[image_counts.index(max_images)]\n",
    "        \n",
    "        print(f\"Average images per PDF: {avg_images:.2f}\")\n",
    "        print(f\"Maximum images in a single PDF: {max_images} (in {max_pdf})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Search for Specific Content in Extracted Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_text_in_pdfs(search_term, batch_dir):\n",
    "    \"\"\"\n",
    "    Search for a specific term in the extracted text of PDFs.\n",
    "    \n",
    "    Args:\n",
    "        search_term: Term to search for\n",
    "        batch_dir: Directory containing processed PDFs\n",
    "    \n",
    "    Returns:\n",
    "        List of dictionaries with search results\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    # Get all subdirectories in the batch directory\n",
    "    pdf_dirs = [d for d in os.listdir(batch_dir) if os.path.isdir(os.path.join(batch_dir, d))]\n",
    "    \n",
    "    for pdf_dir in pdf_dirs:\n",
    "        text_path = os.path.join(batch_dir, pdf_dir, \"extracted_text.txt\")\n",
    "        \n",
    "        if os.path.exists(text_path):\n",
    "            with open(text_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                text = f.read()\n",
    "            \n",
    "            # Search for the term\n",
    "            if search_term.lower() in text.lower():\n",
    "                # Find context around matches\n",
    "                text_lower = text.lower()\n",
    "                term_lower = search_term.lower()\n",
    "                contexts = []\n",
    "                \n",
    "                offset = 0\n",
    "                while True:\n",
    "                    pos = text_lower.find(term_lower, offset)\n",
    "                    if pos == -1:\n",
    "                        break\n",
    "                    \n",
    "                    # Extract context around the match (100 chars before and after)\n",
    "                    start = max(0, pos - 100)\n",
    "                    end = min(len(text), pos + len(search_term) + 100)\n",
    "                    context = text[start:end]\n",
    "                    \n",
    "                    contexts.append(context)\n",
    "                    offset = pos + len(search_term)\n",
    "                    \n",
    "                    # Limit to 5 contexts per file\n",
    "                    if len(contexts) >= 5:\n",
    "                        break\n",
    "                \n",
    "                results.append({\n",
    "                    \"filename\": pdf_dir,\n",
    "                    \"match_count\": text_lower.count(term_lower),\n",
    "                    \"contexts\": contexts\n",
    "                })\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Allow user to search for terms in the extracted text\n",
    "if 'batch_dir' in locals():\n",
    "    search_term = input(\"Enter a term to search for in the PDF text: \")\n",
    "    \n",
    "    if search_term:\n",
    "        print(f\"Searching for '{search_term}' in processed PDFs...\")\n",
    "        search_results = search_text_in_pdfs(search_term, batch_dir)\n",
    "        \n",
    "        if search_results:\n",
    "            print(f\"Found '{search_term}' in {len(search_results)} PDFs:\\n\")\n",
    "            \n",
    "            for i, result in enumerate(search_results):\n",
    "                print(f\"{i+1}. {result['filename']} - {result['match_count']} matches\")\n",
    "                \n",
    "                # Show the first context for each result\n",
    "                if result['contexts']:\n",
    "                    context = result['contexts'][0]\n",
    "                    highlight = context.replace(\n",
    "                        search_term, \n",
    "                        f\"\\033[1m\\033[91m{search_term}\\033[0m\",\n",
    "                        1\n",
    "                    )\n",
    "                    print(f\"   Context: ...{highlight}...\\n\")\n",
    "        else:\n",
    "            print(f\"No matches found for '{search_term}'\")\n",
    "else:\n",
    "    print(\"No batch processing results available for searching.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Conclusion and Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to use the PDFExtractor class to process PDF files and extract text and images. The extracted content can be used for a variety of applications, including:\n",
    "\n",
    "1. **Text analysis** - Perform text mining, keyword extraction, sentiment analysis, etc.\n",
    "2. **Image analysis** - Analyze extracted images for objects, faces, text, etc.\n",
    "3. **Document classification** - Classify PDFs based on their content\n",
    "4. **Search functionality** - Build a search index for PDF documents\n",
    "5. **Data extraction** - Extract specific information from structured PDF documents\n",
    "\n",
    "For production use, consider:\n",
    "- Improving error handling and logging\n",
    "- Implementing parallel processing for large batches\n",
    "- Adding more advanced text and image analysis\n",
    "- Integrating with a vector database for semantic search\n",
    "- Creating a user interface for easier interaction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
