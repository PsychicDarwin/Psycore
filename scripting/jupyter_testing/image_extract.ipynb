{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import hashlib\n",
    "import os\n",
    "\n",
    "def hash_image(image_data, hash_algorithm='sha256'):\n",
    "    \"\"\"\n",
    "    Generate a hash for image data.\n",
    "    \n",
    "    Args:\n",
    "        image_data: Binary image data\n",
    "        hash_algorithm: Hash algorithm to use ('md5', 'sha1', 'sha256', etc.)\n",
    "    \n",
    "    Returns:\n",
    "        Hash string of the image\n",
    "    \"\"\"\n",
    "    if hash_algorithm == 'md5':\n",
    "        hash_obj = hashlib.md5(image_data)\n",
    "    elif hash_algorithm == 'sha1':\n",
    "        hash_obj = hashlib.sha1(image_data)\n",
    "    elif hash_algorithm == 'sha256':\n",
    "        hash_obj = hashlib.sha256(image_data)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported hash algorithm: {hash_algorithm}\")\n",
    "    \n",
    "    return hash_obj.hexdigest()\n",
    "\n",
    "# Open PDF file\n",
    "pdf_path = \"Norfolk_Public_Review_PR_RFI_Launch__Template_V2_.pdf\"\n",
    "output_dir = \"extracted_images\"\n",
    "hash_file = \"image_hashes.txt\"\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Open the hash file for writing\n",
    "with open(hash_file, \"w\") as hash_f:\n",
    "    hash_f.write(\"Filename, Hash (SHA-256), Page Number, Image Index\\n\")\n",
    "    \n",
    "    # Open the PDF\n",
    "    pdf = fitz.open(pdf_path)\n",
    "    \n",
    "    # Dictionary to track hashes for duplicate detection\n",
    "    hash_to_files = {}\n",
    "    \n",
    "    # Track total images\n",
    "    image_count = 0\n",
    "    \n",
    "    # Process each page\n",
    "    for page_num in range(len(pdf)):\n",
    "        page = pdf[page_num]\n",
    "        image_list = page.get_images()\n",
    "        \n",
    "        # Process each image on the page\n",
    "        for img_index, img in enumerate(image_list):\n",
    "            xref = img[0]\n",
    "            base_image = pdf.extract_image(xref)\n",
    "            image_bytes = base_image[\"image\"]\n",
    "            \n",
    "            # Hash the image data\n",
    "            img_hash = hash_image(image_bytes)\n",
    "            \n",
    "            # Create a filename\n",
    "            filename = f\"output_image_{page_num}_{img_index}.png\"\n",
    "            file_path = os.path.join(output_dir, filename)\n",
    "            \n",
    "            # Track the hash for duplicate detection\n",
    "            if img_hash in hash_to_files:\n",
    "                hash_to_files[img_hash].append(filename)\n",
    "                is_duplicate = True\n",
    "            else:\n",
    "                hash_to_files[img_hash] = [filename]\n",
    "                is_duplicate = False\n",
    "            \n",
    "            # Save image information to the hash file\n",
    "            duplicate_info = \" (DUPLICATE)\" if is_duplicate else \"\"\n",
    "            hash_f.write(f\"{filename}, {img_hash}, {page_num+1}, {img_index}{duplicate_info}\\n\")\n",
    "            \n",
    "            # Save the image - you can choose to skip duplicates if desired\n",
    "            if not is_duplicate:  # Uncomment this if you want to skip saving duplicates\n",
    "                with open(file_path, \"wb\") as img_file:\n",
    "                    img_file.write(image_bytes)\n",
    "                \n",
    "            image_count += 1\n",
    "            print(f\"Processed image {image_count}: {filename} - Hash: {img_hash[:10]}...\")\n",
    "\n",
    "    # Write duplicate summary at the end of the hash file\n",
    "    hash_f.write(\"\\n\\nDuplicate Images Summary:\\n\")\n",
    "    for img_hash, files in hash_to_files.items():\n",
    "        if len(files) > 1:\n",
    "            hash_f.write(f\"\\nHash {img_hash} appears in:\\n\")\n",
    "            for f in files:\n",
    "                hash_f.write(f\"  - {f}\\n\")\n",
    "\n",
    "print(f\"\\nExtracted and hashed {image_count} images from {pdf_path}\")\n",
    "print(f\"Image files saved to: {output_dir}\")\n",
    "print(f\"Hash information saved to: {hash_file}\")\n",
    "\n",
    "# Close the PDF\n",
    "pdf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All hashes written to image_hashes.txt\n"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "import os\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "def hash_image(image_path, hash_algorithm='md5'):\n",
    "    \"\"\"\n",
    "    Generate a hash for an image file.\n",
    "    \n",
    "    Args:\n",
    "        image_path: Path to the image file\n",
    "        hash_algorithm: Hash algorithm to use ('md5', 'sha1', 'sha256', etc.)\n",
    "    \n",
    "    Returns:\n",
    "        Hash string of the image\n",
    "    \"\"\"\n",
    "    # Open the image file\n",
    "    with open(image_path, 'rb') as f:\n",
    "        image_data = f.read()\n",
    "    \n",
    "    # Create hash\n",
    "    if hash_algorithm == 'md5':\n",
    "        hash_obj = hashlib.md5(image_data)\n",
    "    elif hash_algorithm == 'sha1':\n",
    "        hash_obj = hashlib.sha1(image_data)\n",
    "    elif hash_algorithm == 'sha256':\n",
    "        hash_obj = hashlib.sha256(image_data)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported hash algorithm: {hash_algorithm}\")\n",
    "    \n",
    "    return hash_obj.hexdigest()\n",
    "\n",
    "# Example usage:\n",
    "image_dir = \".\"  # Current directory where images are stored\n",
    "output_file = \"image_hashes.txt\"\n",
    "\n",
    "# Get all PNG files\n",
    "image_files = [f for f in os.listdir(image_dir) if f.startswith(\"output_image_\") and f.endswith(\".png\")]\n",
    "\n",
    "# Calculate hash for each image and write to file\n",
    "with open(output_file, \"w\") as out_f:\n",
    "    for img_file in sorted(image_files):\n",
    "        img_path = os.path.join(image_dir, img_file)\n",
    "        img_hash = hash_image(img_path, 'sha256')  # Using SHA-256 for stronger hashing\n",
    "        out_f.write(f\"{img_file}: {img_hash}\\n\")\n",
    "        print(f\"Hashed {img_file}\")\n",
    "\n",
    "print(f\"All hashes written to {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
