{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q-Learning for Prompt Selection (Predefined Questions)\n",
    "\n",
    "This notebook demonstrates how to use Q-learning to select between original and elaborated prompts using predefined test questions.\n",
    "\n",
    "## Key Components\n",
    "- **States**: Features extracted from the prompt (type, length, complexity)\n",
    "- **Actions**: Choose between original or elaborated prompt\n",
    "- **Rewards**: Simulated or predefined feedback on which response was better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Add the project root to the path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "from src.flow.prompt_elaborator import PromptElaborator\n",
    "from src.rl.q_learning import QLearningModel, ORIGINAL_PROMPT, ELABORATED_PROMPT\n",
    "from src.model.model_catalogue import ModelCatalogue\n",
    "from src.model.wrappers import ChatModelWrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available multimodal models:\n",
      "- oai_4o_latest\n",
      "- oai_chatgpt_latest\n",
      "- claude_3_sonnet\n",
      "- claude_3_haiku\n",
      "- gemini_1.5_flash\n",
      "- gemini_1.5_8b_flash\n",
      "- gemini_1.5_pro\n",
      "- grok_2_vision\n",
      "- llava_7b\n",
      "- llava_13b\n",
      "- llava_34b\n",
      "- bakllava_7b\n",
      "\n",
      "Using model: claude_3_sonnet\n"
     ]
    }
   ],
   "source": [
    "# Initialize the prompt elaborator\n",
    "elaborator = PromptElaborator(model_name=\"claude_3_sonnet\")\n",
    "\n",
    "# Initialize the Q-learning model\n",
    "q_model = QLearningModel(\n",
    "    learning_rate=0.1,\n",
    "    exploration_rate=0.3,\n",
    "    save_path=\"../results/q_learning_notebook\"\n",
    ")\n",
    "\n",
    "# Initialize a test model\n",
    "multimodal_models = ModelCatalogue.get_MLLMs()\n",
    "print(\"Available multimodal models:\")\n",
    "for name in multimodal_models.keys():\n",
    "    print(f\"- {name}\")\n",
    "\n",
    "test_model_name = \"claude_3_sonnet\" if \"claude_3_sonnet\" in multimodal_models else list(multimodal_models.keys())[0]\n",
    "print(f\"\\nUsing model: {test_model_name}\")\n",
    "test_model = ChatModelWrapper(multimodal_models[test_model_name]).model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predefined Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of test prompts for different types of queries\n",
    "test_prompts = [\n",
    "    \"Explain the concept of artificial intelligence\",\n",
    "    \"How to implement a binary search algorithm?\"\n",
    "]\n",
    "\n",
    "# Define a function to process a single prompt\n",
    "def process_test_prompt(prompt, feedback=None):\n",
    "    print(f\"\\n{'='*80}\\nProcessing prompt: {prompt}\\n{'='*80}\\n\")\n",
    "    \n",
    "    # Extract features for the state\n",
    "    features = q_model.extract_features(prompt)\n",
    "    print(\"Extracted features:\")\n",
    "    for key, value in features.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "    \n",
    "    # Elaborate the prompt\n",
    "    elaborated_prompt = elaborator(prompt)\n",
    "    \n",
    "    print(\"\\nOriginal prompt:\")\n",
    "    print(prompt)\n",
    "    \n",
    "    print(\"\\nElaborated prompt:\")\n",
    "    print(elaborated_prompt)\n",
    "    \n",
    "    # Select action using Q-learning\n",
    "    action = q_model.select_action(prompt)\n",
    "    action_name = \"Original\" if action == ORIGINAL_PROMPT else \"Elaborated\"\n",
    "    print(f\"\\nQ-learning selected: {action_name} prompt\")\n",
    "    \n",
    "    # Get responses from both prompts\n",
    "    print(\"\\nGetting responses...\")\n",
    "    try:\n",
    "        original_response = test_model.invoke(prompt)\n",
    "        elaborated_response = test_model.invoke(elaborated_prompt)\n",
    "        \n",
    "        # Truncate responses for display\n",
    "        orig_content = original_response.content\n",
    "        elab_content = elaborated_response.content\n",
    "        \n",
    "        print(\"\\nResponse to original prompt:\")\n",
    "        print(orig_content[:500] + \"...\" if len(orig_content) > 500 else orig_content)\n",
    "        \n",
    "        print(\"\\nResponse to elaborated prompt:\")\n",
    "        print(elab_content[:500] + \"...\" if len(elab_content) > 500 else elab_content)\n",
    "        \n",
    "        # Process feedback if provided\n",
    "        if feedback is not None:\n",
    "            print(f\"\\nPredefined feedback: {feedback}\")\n",
    "            q_model.process_feedback(feedback)\n",
    "            \n",
    "            # Show updated stats\n",
    "            stats = q_model.get_stats()\n",
    "            print(\"\\nUpdated Q-learning stats:\")\n",
    "            print(f\"Total updates: {stats['total_updates']}\")\n",
    "            print(f\"Original selections: {stats['original_percentage']:.1f}%\")\n",
    "            print(f\"Elaborated selections: {stats['elaborated_percentage']:.1f}%\")\n",
    "            print(f\"Exploration rate: {stats['exploration_rate']:.3f}\")\n",
    "            \n",
    "            # Save the model\n",
    "            q_model.save()\n",
    "            print(\"\\nQ-learning model updated and saved\")\n",
    "        else:\n",
    "            print(\"\\nNo feedback provided - skipping Q-learning update\")\n",
    "        \n",
    "        return original_response, elaborated_response\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting responses: {e}\")\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Tests with Predefined Feedback\n",
    "\n",
    "Let's run through our test prompts with predefined feedback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-04 18:56:32,734 - langchain_aws.llms.bedrock - INFO - Using Bedrock Invoke API to generate response\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Processing prompt: Explain the concept of artificial intelligence\n",
      "================================================================================\n",
      "\n",
      "Extracted features:\n",
      "  has_image: False\n",
      "  length_category: medium\n",
      "  is_question: False\n",
      "  prompt_type: descriptive\n",
      "  complexity: simple\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-04 18:56:42,430 - langchain_aws.chat_models.bedrock - INFO - The message received from Bedrock: Artificial intelligence (AI) is a rapidly evolving field that encompasses a wide range of techniques and technologies aimed at creating intelligent systems that can perceive, learn, reason, and act in ways that mimic or even surpass human capabilities. To effectively explain this complex concept, please provide a detailed and comprehensive response covering the following aspects:\n",
      "\n",
      "1. Historical Background:\n",
      "   - Briefly introduce the origins and key milestones in the development of AI, highlighting pioneers and their contributions.\n",
      "   - Explain the driving forces behind the pursuit of artificial intelligence, such as the desire to automate tasks, enhance decision-making processes, and push the boundaries of human knowledge.\n",
      "\n",
      "2. Definition and Components:\n",
      "   - Provide a clear and concise definition of artificial intelligence, highlighting its fundamental goals and characteristics.\n",
      "   - Discuss the main components of AI systems, including machine learning, natural language processing, computer vision, robotics, and expert systems.\n",
      "   - Explain the differences between narrow AI (specialized systems designed for specific tasks) and general AI (systems with broad, human-like intelligence).\n",
      "\n",
      "3. Approaches and Techniques:\n",
      "   - Describe the main approaches to AI, such as rule-based systems, machine learning (supervised, unsupervised, and reinforcement learning), deep learning, and symbolic reasoning.\n",
      "   - Explain the key techniques and algorithms used in AI, such as neural networks, decision trees, genetic algorithms, and fuzzy logic.\n",
      "   - Provide examples of how these techniques are applied in various domains, such as computer vision, natural language processing, robotics, and game-playing.\n",
      "\n",
      "4. Applications and Impact:\n",
      "   - Highlight the current and potential applications of AI across various industries and domains, such as healthcare, finance, transportation, education, and entertainment.\n",
      "   - Discuss the societal, economic, and ethical implications of AI, including issues like job displacement, privacy concerns, bias and fairness, and the potential risks of advanced AI systems.\n",
      "   - Address the challenges and limitations of AI, such as the need for large datasets, computational power, and the difficulty of developing truly intelligent systems.\n",
      "\n",
      "5. Future Directions and Trends:\n",
      "   - Explore the emerging trends and future directions in AI research and development, such as explainable AI, multi-agent systems, human-AI collaboration, and the pursuit of artificial general intelligence (AGI).\n",
      "   - Discuss the potential impacts of AI on society, science, and humanity as a whole, both positive and negative.\n",
      "\n",
      "Please ensure that your response is well-structured, informative, and accessible to a general audience, while still providing sufficient depth and technical details for a comprehensive understanding of artificial intelligence.\n",
      "2025-04-04 18:56:42,434 - src.rl.q_learning - INFO - Exploiting: Selected action 1 based on Q-values [0.0, 0.0]\n",
      "2025-04-04 18:56:42,437 - langchain_aws.llms.bedrock - INFO - Using Bedrock Invoke API to generate response\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original prompt:\n",
      "Explain the concept of artificial intelligence\n",
      "\n",
      "Elaborated prompt:\n",
      "Artificial intelligence (AI) is a rapidly evolving field that encompasses a wide range of techniques and technologies aimed at creating intelligent systems that can perceive, learn, reason, and act in ways that mimic or even surpass human capabilities. To effectively explain this complex concept, please provide a detailed and comprehensive response covering the following aspects:\n",
      "\n",
      "1. Historical Background:\n",
      "   - Briefly introduce the origins and key milestones in the development of AI, highlighting pioneers and their contributions.\n",
      "   - Explain the driving forces behind the pursuit of artificial intelligence, such as the desire to automate tasks, enhance decision-making processes, and push the boundaries of human knowledge.\n",
      "\n",
      "2. Definition and Components:\n",
      "   - Provide a clear and concise definition of artificial intelligence, highlighting its fundamental goals and characteristics.\n",
      "   - Discuss the main components of AI systems, including machine learning, natural language processing, computer vision, robotics, and expert systems.\n",
      "   - Explain the differences between narrow AI (specialized systems designed for specific tasks) and general AI (systems with broad, human-like intelligence).\n",
      "\n",
      "3. Approaches and Techniques:\n",
      "   - Describe the main approaches to AI, such as rule-based systems, machine learning (supervised, unsupervised, and reinforcement learning), deep learning, and symbolic reasoning.\n",
      "   - Explain the key techniques and algorithms used in AI, such as neural networks, decision trees, genetic algorithms, and fuzzy logic.\n",
      "   - Provide examples of how these techniques are applied in various domains, such as computer vision, natural language processing, robotics, and game-playing.\n",
      "\n",
      "4. Applications and Impact:\n",
      "   - Highlight the current and potential applications of AI across various industries and domains, such as healthcare, finance, transportation, education, and entertainment.\n",
      "   - Discuss the societal, economic, and ethical implications of AI, including issues like job displacement, privacy concerns, bias and fairness, and the potential risks of advanced AI systems.\n",
      "   - Address the challenges and limitations of AI, such as the need for large datasets, computational power, and the difficulty of developing truly intelligent systems.\n",
      "\n",
      "5. Future Directions and Trends:\n",
      "   - Explore the emerging trends and future directions in AI research and development, such as explainable AI, multi-agent systems, human-AI collaboration, and the pursuit of artificial general intelligence (AGI).\n",
      "   - Discuss the potential impacts of AI on society, science, and humanity as a whole, both positive and negative.\n",
      "\n",
      "Please ensure that your response is well-structured, informative, and accessible to a general audience, while still providing sufficient depth and technical details for a comprehensive understanding of artificial intelligence.\n",
      "\n",
      "Q-learning selected: Elaborated prompt\n",
      "\n",
      "Getting responses...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-04 18:56:49,907 - langchain_aws.chat_models.bedrock - INFO - The message received from Bedrock: Artificial Intelligence (AI) is a branch of computer science that focuses on developing machines and systems that can perform tasks that typically require human intelligence, such as learning, problem-solving, decision-making, perception, and reasoning. The goal of AI is to create intelligent agents that can analyze data, recognize patterns, and make decisions or take actions based on that analysis.\n",
      "\n",
      "AI involves several approaches and techniques, including:\n",
      "\n",
      "1. Machine Learning: Machine learning is a subset of AI that involves training algorithms to learn from data and make predictions or decisions without being explicitly programmed. This includes supervised learning (using labeled data), unsupervised learning (finding patterns in unlabeled data), and reinforcement learning (learning through trial and error).\n",
      "\n",
      "2. Neural Networks: Neural networks are a type of machine learning algorithm inspired by the human brain's neural networks. They consist of interconnected nodes that process and transmit information, allowing the system to learn and make decisions based on the input data.\n",
      "\n",
      "3. Natural Language Processing (NLP): NLP is a field of AI that deals with the interaction between computers and human languages. It enables machines to understand, interpret, and generate human language, allowing for applications like speech recognition, text analysis, and language translation.\n",
      "\n",
      "4. Computer Vision: Computer vision is the field of AI that enables computers to interpret and understand digital images and videos, enabling applications like object recognition, facial recognition, and image analysis.\n",
      "\n",
      "5. Robotics: AI is also used in robotics, enabling robots to perceive their environment, make decisions, and perform tasks autonomously or with human guidance.\n",
      "\n",
      "6. Expert Systems: Expert systems are AI programs designed to emulate the decision-making ability of human experts in specific domains, such as medical diagnosis or financial analysis.\n",
      "\n",
      "AI has numerous applications across various industries, including healthcare, finance, transportation, entertainment, and many more. However, it also raises ethical concerns related to privacy, bias, and the potential impact on employment and society.\n",
      "\n",
      "The development of AI requires a multidisciplinary approach, combining computer science, mathematics, psychology, linguistics, and other fields to create intelligent systems that can support and enhance human capabilities.\n",
      "2025-04-04 18:56:49,912 - langchain_aws.llms.bedrock - INFO - Using Bedrock Invoke API to generate response\n",
      "2025-04-04 18:56:55,959 - root - ERROR - Error raised by bedrock service: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many requests, please wait before trying again.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error getting responses: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many requests, please wait before trying again.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predefined feedback to simulate user preferences\n",
    "# This could be replaced with your own judgments after seeing the responses\n",
    "predefined_feedback = [\n",
    "    \"elaborated\",  # For explanatory questions, elaborate is often better\n",
    "    \"original\"    # For how-to questions\n",
    "]\n",
    "\n",
    "# Test the first prompt to see responses without giving feedback\n",
    "process_test_prompt(test_prompts[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you've seen the responses, you can run all tests with predefined feedback. You can modify the feedback if needed based on your own judgment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-04 18:57:05,304 - langchain_aws.llms.bedrock - INFO - Using Bedrock Invoke API to generate response\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Processing prompt: Explain the concept of artificial intelligence\n",
      "================================================================================\n",
      "\n",
      "Extracted features:\n",
      "  has_image: False\n",
      "  length_category: medium\n",
      "  is_question: False\n",
      "  prompt_type: descriptive\n",
      "  complexity: simple\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-04 18:57:12,370 - langchain_aws.chat_models.bedrock - INFO - The message received from Bedrock: Artificial intelligence (AI) is a broad and fascinating field that involves the development of intelligent systems and machines capable of performing tasks that typically require human-like cognition, such as learning, problem-solving, reasoning, perception, and decision-making. To provide a comprehensive explanation of AI, please address the following points:\n",
      "\n",
      "1. Definition and History:\n",
      "   - Provide a concise definition of artificial intelligence.\n",
      "   - Briefly discuss the historical milestones and pioneers in the development of AI.\n",
      "\n",
      "2. Applications and Domains:\n",
      "   - Describe some major domains and applications where AI is currently being utilized or has the potential for significant impact.\n",
      "   - Provide specific examples of how AI is being applied in fields like healthcare, finance, transportation, and entertainment.\n",
      "\n",
      "3. Techniques and Approaches:\n",
      "   - Explain the key techniques and approaches used in AI, such as machine learning, deep learning, natural language processing, computer vision, and expert systems.\n",
      "   - Discuss the concept of artificial neural networks and how they are used to enable machine learning.\n",
      "\n",
      "4. Types of AI:\n",
      "   - Distinguish between different types of AI, such as narrow/specialized AI, general AI (AGI), and superintelligent AI.\n",
      "   - Briefly explain the current state of AI development and the challenges in achieving AGI or superintelligent AI.\n",
      "\n",
      "5. Ethical Considerations:\n",
      "   - Discuss some ethical concerns and potential risks associated with the development and deployment of AI systems.\n",
      "   - Address issues such as privacy, bias, accountability, and the impact of AI on employment and societal structures.\n",
      "\n",
      "6. Future Prospects:\n",
      "   - Speculate on the potential future advancements and implications of AI technology.\n",
      "   - Discuss the potential benefits and risks of continued AI development and deployment.\n",
      "\n",
      "Please provide a well-structured, comprehensive, and objective explanation of artificial intelligence, covering these key aspects while maintaining clarity and conciseness in your response.\n",
      "2025-04-04 18:57:12,376 - src.rl.q_learning - INFO - Exploiting: Selected action 0 based on Q-values [0.0, 0.0]\n",
      "2025-04-04 18:57:12,379 - langchain_aws.llms.bedrock - INFO - Using Bedrock Invoke API to generate response\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original prompt:\n",
      "Explain the concept of artificial intelligence\n",
      "\n",
      "Elaborated prompt:\n",
      "Artificial intelligence (AI) is a broad and fascinating field that involves the development of intelligent systems and machines capable of performing tasks that typically require human-like cognition, such as learning, problem-solving, reasoning, perception, and decision-making. To provide a comprehensive explanation of AI, please address the following points:\n",
      "\n",
      "1. Definition and History:\n",
      "   - Provide a concise definition of artificial intelligence.\n",
      "   - Briefly discuss the historical milestones and pioneers in the development of AI.\n",
      "\n",
      "2. Applications and Domains:\n",
      "   - Describe some major domains and applications where AI is currently being utilized or has the potential for significant impact.\n",
      "   - Provide specific examples of how AI is being applied in fields like healthcare, finance, transportation, and entertainment.\n",
      "\n",
      "3. Techniques and Approaches:\n",
      "   - Explain the key techniques and approaches used in AI, such as machine learning, deep learning, natural language processing, computer vision, and expert systems.\n",
      "   - Discuss the concept of artificial neural networks and how they are used to enable machine learning.\n",
      "\n",
      "4. Types of AI:\n",
      "   - Distinguish between different types of AI, such as narrow/specialized AI, general AI (AGI), and superintelligent AI.\n",
      "   - Briefly explain the current state of AI development and the challenges in achieving AGI or superintelligent AI.\n",
      "\n",
      "5. Ethical Considerations:\n",
      "   - Discuss some ethical concerns and potential risks associated with the development and deployment of AI systems.\n",
      "   - Address issues such as privacy, bias, accountability, and the impact of AI on employment and societal structures.\n",
      "\n",
      "6. Future Prospects:\n",
      "   - Speculate on the potential future advancements and implications of AI technology.\n",
      "   - Discuss the potential benefits and risks of continued AI development and deployment.\n",
      "\n",
      "Please provide a well-structured, comprehensive, and objective explanation of artificial intelligence, covering these key aspects while maintaining clarity and conciseness in your response.\n",
      "\n",
      "Q-learning selected: Original prompt\n",
      "\n",
      "Getting responses...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-04 18:57:18,268 - root - ERROR - Error raised by bedrock service: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many requests, please wait before trying again.\n",
      "2025-04-04 18:57:18,273 - langchain_aws.llms.bedrock - INFO - Using Bedrock Invoke API to generate response\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error getting responses: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many requests, please wait before trying again.\n",
      "\n",
      "================================================================================\n",
      "Processing prompt: How to implement a binary search algorithm?\n",
      "================================================================================\n",
      "\n",
      "Extracted features:\n",
      "  has_image: False\n",
      "  length_category: medium\n",
      "  is_question: True\n",
      "  prompt_type: procedural\n",
      "  complexity: simple\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-04 18:57:21,673 - root - ERROR - Error raised by bedrock service: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many requests, please wait before trying again.\n"
     ]
    },
    {
     "ename": "ThrottlingException",
     "evalue": "An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many requests, please wait before trying again.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mThrottlingException\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, prompt \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(test_prompts):\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(predefined_feedback):\n\u001b[1;32m----> 4\u001b[0m         \u001b[43mprocess_test_prompt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredefined_feedback\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[16], line 18\u001b[0m, in \u001b[0;36mprocess_test_prompt\u001b[1;34m(prompt, feedback)\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Elaborate the prompt\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m elaborated_prompt \u001b[38;5;241m=\u001b[39m \u001b[43melaborator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mOriginal prompt:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(prompt)\n",
      "File \u001b[1;32mc:\\Users\\anast\\Documents\\Darwin\\Psycore\\src\\flow\\prompt_elaborator.py:66\u001b[0m, in \u001b[0;36mPromptElaborator.__call__\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;124;03mElaborate on a prompt using the LLM.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;124;03m    The elaborated prompt\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m# Call the elaboration chain\u001b[39;00m\n\u001b[1;32m---> 66\u001b[0m elaborated_prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43melaboration_chain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43moriginal_prompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m# Clean up the elaborated prompt (remove quotes if present)\u001b[39;00m\n\u001b[0;32m     69\u001b[0m elaborated_prompt \u001b[38;5;241m=\u001b[39m elaborated_prompt\u001b[38;5;241m.\u001b[39mstrip()\n",
      "File \u001b[1;32mc:\\Users\\anast\\Documents\\Darwin\\Psycore\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:181\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    179\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    180\u001b[0m     emit_warning()\n\u001b[1;32m--> 181\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\anast\\Documents\\Darwin\\Psycore\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py:611\u001b[0m, in \u001b[0;36mChain.run\u001b[1;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[0;32m    606\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m(args[\u001b[38;5;241m0\u001b[39m], callbacks\u001b[38;5;241m=\u001b[39mcallbacks, tags\u001b[38;5;241m=\u001b[39mtags, metadata\u001b[38;5;241m=\u001b[39mmetadata)[\n\u001b[0;32m    607\u001b[0m         _output_key\n\u001b[0;32m    608\u001b[0m     ]\n\u001b[0;32m    610\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[1;32m--> 611\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m[\n\u001b[0;32m    612\u001b[0m         _output_key\n\u001b[0;32m    613\u001b[0m     ]\n\u001b[0;32m    615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[0;32m    616\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    617\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`run` supported with either positional arguments or keyword arguments,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    618\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m but none were provided.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    619\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\anast\\Documents\\Darwin\\Psycore\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:181\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    179\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    180\u001b[0m     emit_warning()\n\u001b[1;32m--> 181\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\anast\\Documents\\Darwin\\Psycore\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py:389\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[0;32m    357\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[0;32m    358\u001b[0m \n\u001b[0;32m    359\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;124;03m        `Chain.output_keys`.\u001b[39;00m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    382\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    383\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks,\n\u001b[0;32m    384\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m: tags,\n\u001b[0;32m    385\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[0;32m    386\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: run_name,\n\u001b[0;32m    387\u001b[0m }\n\u001b[1;32m--> 389\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    391\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRunnableConfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    392\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    393\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_run_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_run_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    394\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\anast\\Documents\\Darwin\\Psycore\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py:170\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    169\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[1;32m--> 170\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    171\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "File \u001b[1;32mc:\\Users\\anast\\Documents\\Darwin\\Psycore\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py:160\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_inputs(inputs)\n\u001b[0;32m    159\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 160\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    162\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[0;32m    163\u001b[0m     )\n\u001b[0;32m    165\u001b[0m     final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[0;32m    166\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[0;32m    167\u001b[0m     )\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\anast\\Documents\\Darwin\\Psycore\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py:126\u001b[0m, in \u001b[0;36mLLMChain._call\u001b[1;34m(self, inputs, run_manager)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_call\u001b[39m(\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    123\u001b[0m     inputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[0;32m    124\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    125\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m--> 126\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_outputs(response)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\anast\\Documents\\Darwin\\Psycore\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py:138\u001b[0m, in \u001b[0;36mLLMChain.generate\u001b[1;34m(self, input_list, run_manager)\u001b[0m\n\u001b[0;32m    136\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m run_manager\u001b[38;5;241m.\u001b[39mget_child() \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm, BaseLanguageModel):\n\u001b[1;32m--> 138\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    139\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    140\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    142\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    143\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    145\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm\u001b[38;5;241m.\u001b[39mbind(stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_kwargs)\u001b[38;5;241m.\u001b[39mbatch(\n\u001b[0;32m    146\u001b[0m         cast(List, prompts), {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks}\n\u001b[0;32m    147\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\anast\\Documents\\Darwin\\Psycore\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:860\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[1;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    852\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[0;32m    853\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    854\u001b[0m     prompts: \u001b[38;5;28mlist\u001b[39m[PromptValue],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    857\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    858\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m    859\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[1;32m--> 860\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\anast\\Documents\\Darwin\\Psycore\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:690\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[0;32m    688\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    689\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 690\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    691\u001b[0m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    692\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    693\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    694\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    695\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    696\u001b[0m         )\n\u001b[0;32m    697\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    698\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[1;32mc:\\Users\\anast\\Documents\\Darwin\\Psycore\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:925\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    923\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    924\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 925\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    926\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    927\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    928\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    929\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\anast\\Documents\\Darwin\\Psycore\\.venv\\Lib\\site-packages\\langchain_aws\\chat_models\\bedrock.py:581\u001b[0m, in \u001b[0;36mChatBedrock._generate\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    578\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stop:\n\u001b[0;32m    579\u001b[0m         params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop_sequences\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m stop\n\u001b[1;32m--> 581\u001b[0m     completion, tool_calls, llm_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_input_and_invoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    582\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    583\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    584\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    585\u001b[0m \u001b[43m        \u001b[49m\u001b[43msystem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformatted_messages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    587\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    588\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    589\u001b[0m \u001b[38;5;66;03m# usage metadata\u001b[39;00m\n\u001b[0;32m    590\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m usage \u001b[38;5;241m:=\u001b[39m llm_output\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musage\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\anast\\Documents\\Darwin\\Psycore\\.venv\\Lib\\site-packages\\langchain_aws\\llms\\bedrock.py:847\u001b[0m, in \u001b[0;36mBedrockBase._prepare_input_and_invoke\u001b[1;34m(self, prompt, system, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    845\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    846\u001b[0m         run_manager\u001b[38;5;241m.\u001b[39mon_llm_error(e)\n\u001b[1;32m--> 847\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    849\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stop \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    850\u001b[0m     text \u001b[38;5;241m=\u001b[39m enforce_stop_tokens(text, stop)\n",
      "File \u001b[1;32mc:\\Users\\anast\\Documents\\Darwin\\Psycore\\.venv\\Lib\\site-packages\\langchain_aws\\llms\\bedrock.py:833\u001b[0m, in \u001b[0;36mBedrockBase._prepare_input_and_invoke\u001b[1;34m(self, prompt, system, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    831\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRequest body sent to bedrock: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrequest_options\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    832\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing Bedrock Invoke API to generate response\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 833\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrequest_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    835\u001b[0m (\n\u001b[0;32m    836\u001b[0m     text,\n\u001b[0;32m    837\u001b[0m     tool_calls,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    840\u001b[0m     stop_reason,\n\u001b[0;32m    841\u001b[0m ) \u001b[38;5;241m=\u001b[39m LLMInputOutputAdapter\u001b[38;5;241m.\u001b[39mprepare_output(provider, response)\u001b[38;5;241m.\u001b[39mvalues()\n\u001b[0;32m    842\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResponse received from Bedrock: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\anast\\Documents\\Darwin\\Psycore\\.venv\\Lib\\site-packages\\botocore\\client.py:569\u001b[0m, in \u001b[0;36mClientCreator._create_api_method.<locals>._api_call\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    565\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    566\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpy_operation_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m() only accepts keyword arguments.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    567\u001b[0m     )\n\u001b[0;32m    568\u001b[0m \u001b[38;5;66;03m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[1;32m--> 569\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_api_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\anast\\Documents\\Darwin\\Psycore\\.venv\\Lib\\site-packages\\botocore\\client.py:1023\u001b[0m, in \u001b[0;36mBaseClient._make_api_call\u001b[1;34m(self, operation_name, api_params)\u001b[0m\n\u001b[0;32m   1019\u001b[0m     error_code \u001b[38;5;241m=\u001b[39m error_info\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQueryErrorCode\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m error_info\u001b[38;5;241m.\u001b[39mget(\n\u001b[0;32m   1020\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCode\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1021\u001b[0m     )\n\u001b[0;32m   1022\u001b[0m     error_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mfrom_code(error_code)\n\u001b[1;32m-> 1023\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[0;32m   1024\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1025\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parsed_response\n",
      "\u001b[1;31mThrottlingException\u001b[0m: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many requests, please wait before trying again."
     ]
    }
   ],
   "source": [
    "# Process all test prompts with predefined feedback\n",
    "for i, prompt in enumerate(test_prompts):\n",
    "    if i < len(predefined_feedback):\n",
    "        process_test_prompt(prompt, predefined_feedback[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Current Q-Learning Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Q-Learning Statistics:\n",
      "Total updates: 0\n",
      "Original prompt selections: 2 (40.0%)\n",
      "Elaborated prompt selections: 3 (60.0%)\n",
      "Current exploration rate: 0.300\n",
      "Q-table size: 2 states\n"
     ]
    }
   ],
   "source": [
    "# Get and display current stats\n",
    "stats = q_model.get_stats()\n",
    "\n",
    "print(f\"Current Q-Learning Statistics:\")\n",
    "print(f\"Total updates: {stats['total_updates']}\")\n",
    "print(f\"Original prompt selections: {stats['original_selected']} ({stats['original_percentage']:.1f}%)\")\n",
    "print(f\"Elaborated prompt selections: {stats['elaborated_selected']} ({stats['elaborated_percentage']:.1f}%)\")\n",
    "print(f\"Current exploration rate: {stats['exploration_rate']:.3f}\")\n",
    "print(f\"Q-table size: {stats['q_table_size']} states\")\n",
    "\n",
    "# Show recent history if available\n",
    "if 'history' in stats and stats['history']:\n",
    "    print(\"\\nRecent learning history:\")\n",
    "    for i, entry in enumerate(stats['history'][-5:]):\n",
    "        print(f\"Entry {i+1}:\")\n",
    "        print(f\"  Action: {entry['action']}\")\n",
    "        print(f\"  Reward: {entry['reward']}\")\n",
    "        print(f\"  New Q-value: {entry['new_q_value']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine the Q-Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q-Table (showing up to 10 entries):\n",
      "--------------------------------------------------------------------------------\n",
      "State                                              | Original Q-Value | Elaborated Q-Value\n",
      "--------------------------------------------------------------------------------\n",
      "complexity:simple, has_image:False, is_question... |          0.0000 |          0.0000\n",
      "complexity:simple, has_image:False, is_question... |          0.0000 |          0.0000\n"
     ]
    }
   ],
   "source": [
    "# Function to display the Q-table in a readable format\n",
    "def display_q_table(q_table, limit=10):\n",
    "    print(f\"Q-Table (showing up to {limit} entries):\")\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"{'State':<50} | {'Original Q-Value':>15} | {'Elaborated Q-Value':>15}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    # Convert the state keys to a more readable format\n",
    "    for i, (state_key, q_values) in enumerate(q_table.items()):\n",
    "        if i >= limit:\n",
    "            print(f\"... and {len(q_table) - limit} more entries\")\n",
    "            break\n",
    "            \n",
    "        # Make the state key more readable\n",
    "        readable_state = state_key.replace(\"|\", \", \")\n",
    "        if len(readable_state) > 50:\n",
    "            readable_state = readable_state[:47] + \"...\"\n",
    "            \n",
    "        print(f\"{readable_state:<50} | {q_values[0]:15.4f} | {q_values[1]:15.4f}\")\n",
    "\n",
    "# Display the Q-table\n",
    "display_q_table(q_model.q_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Test Prompt\n",
    "\n",
    "Here you can test the trained model with your own prompt to see which prompt type it selects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-04 18:58:27,410 - langchain_aws.llms.bedrock - INFO - Using Bedrock Invoke API to generate response\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Processing prompt: Explain the concept of reinforcement learning in AI\n",
      "================================================================================\n",
      "\n",
      "Extracted features:\n",
      "  has_image: False\n",
      "  length_category: long\n",
      "  is_question: False\n",
      "  prompt_type: descriptive\n",
      "  complexity: simple\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-04 18:58:33,538 - langchain_aws.chat_models.bedrock - INFO - The message received from Bedrock: Reinforcement learning is a fundamental concept in artificial intelligence that deals with how an agent can learn to make optimal decisions by interacting with its environment. I'd like you to provide a detailed and easy-to-understand explanation of this concept, covering the following points:\n",
      "\n",
      "1. **Introduction**: Begin with a brief overview of what reinforcement learning is and why it's important in AI.\n",
      "\n",
      "2. **Key Components**: Explain the key components of a reinforcement learning system, such as the agent, environment, actions, rewards, and state transitions.\n",
      "\n",
      "3. **Learning Process**: Describe how the agent learns from its experiences, highlighting the exploration-exploitation trade-off and the role of rewards in shaping the agent's behavior.\n",
      "\n",
      "4. **Algorithms**: Provide an overview of some popular reinforcement learning algorithms, such as Q-learning, SARSA, and policy gradient methods. You can briefly explain how they work and their strengths and weaknesses.\n",
      "\n",
      "5. **Applications**: Discuss real-world applications of reinforcement learning, such as game playing (e.g., Chess, Go), robotics, recommendation systems, and autonomous systems like self-driving cars.\n",
      "\n",
      "6. **Challenges and Future Directions**: Mention some of the challenges and limitations of current reinforcement learning techniques, as well as potential future research directions in this field.\n",
      "\n",
      "Please use clear and concise language, and feel free to include examples, diagrams, or analogies to illustrate key concepts. Your explanation should be accessible to readers with a general understanding of AI but without prior knowledge of reinforcement learning.\n",
      "2025-04-04 18:58:33,541 - src.rl.q_learning - INFO - Exploring: Randomly selected action 1\n",
      "2025-04-04 18:58:33,544 - langchain_aws.llms.bedrock - INFO - Using Bedrock Invoke API to generate response\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original prompt:\n",
      "Explain the concept of reinforcement learning in AI\n",
      "\n",
      "Elaborated prompt:\n",
      "Reinforcement learning is a fundamental concept in artificial intelligence that deals with how an agent can learn to make optimal decisions by interacting with its environment. I'd like you to provide a detailed and easy-to-understand explanation of this concept, covering the following points:\n",
      "\n",
      "1. **Introduction**: Begin with a brief overview of what reinforcement learning is and why it's important in AI.\n",
      "\n",
      "2. **Key Components**: Explain the key components of a reinforcement learning system, such as the agent, environment, actions, rewards, and state transitions.\n",
      "\n",
      "3. **Learning Process**: Describe how the agent learns from its experiences, highlighting the exploration-exploitation trade-off and the role of rewards in shaping the agent's behavior.\n",
      "\n",
      "4. **Algorithms**: Provide an overview of some popular reinforcement learning algorithms, such as Q-learning, SARSA, and policy gradient methods. You can briefly explain how they work and their strengths and weaknesses.\n",
      "\n",
      "5. **Applications**: Discuss real-world applications of reinforcement learning, such as game playing (e.g., Chess, Go), robotics, recommendation systems, and autonomous systems like self-driving cars.\n",
      "\n",
      "6. **Challenges and Future Directions**: Mention some of the challenges and limitations of current reinforcement learning techniques, as well as potential future research directions in this field.\n",
      "\n",
      "Please use clear and concise language, and feel free to include examples, diagrams, or analogies to illustrate key concepts. Your explanation should be accessible to readers with a general understanding of AI but without prior knowledge of reinforcement learning.\n",
      "\n",
      "Q-learning selected: Elaborated prompt\n",
      "\n",
      "Getting responses...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-04 18:58:41,988 - langchain_aws.chat_models.bedrock - INFO - The message received from Bedrock: Reinforcement learning is a type of machine learning technique that deals with how software agents ought to take actions in an environment to maximize some notion of cumulative reward. It is inspired by the way humans and animals learn from experience through trial-and-error interactions with their environment.\n",
      "\n",
      "In reinforcement learning, an agent (the learner or decision-maker) interacts with an environment by taking actions and receiving rewards or penalties based on the consequences of those actions. The goal of the agent is to learn a policy, which is a mapping from perceived environmental states to actions, that maximizes the expected cumulative reward over time.\n",
      "\n",
      "The key elements of reinforcement learning are:\n",
      "\n",
      "1. Environment: The world or system in which the agent operates and interacts with.\n",
      "2. Agent: The software entity that takes actions and learns from its experiences.\n",
      "3. State: The current situation or condition of the environment as perceived by the agent.\n",
      "4. Action: The choices or decisions made by the agent that affect the environment.\n",
      "5. Reward: The feedback signal from the environment that indicates the desirability or undesirability of the agent's actions.\n",
      "\n",
      "The reinforcement learning process works as follows:\n",
      "\n",
      "1. The agent observes the current state of the environment.\n",
      "2. Based on the observed state, the agent selects an action from a set of possible actions.\n",
      "3. The agent performs the chosen action, which causes a change in the environment's state.\n",
      "4. The environment provides a reward (or penalty) to the agent based on the new state resulting from the agent's action.\n",
      "5. The agent learns from this experience by updating its policy to maximize future rewards.\n",
      "\n",
      "This cycle repeats continuously, allowing the agent to learn through trial-and-error interactions with the environment and improve its decision-making over time.\n",
      "\n",
      "Reinforcement learning algorithms can be divided into two main categories: value-based methods (e.g., Q-learning, SARSA) and policy-based methods (e.g., Policy Gradients, Actor-Critic methods). Value-based methods learn a value function that estimates the expected future reward for each state or state-action pair, while policy-based methods directly learn the policy that maps states to actions.\n",
      "\n",
      "Reinforcement learning has been successfully applied in various domains, including robotics, game playing (e.g., AlphaGo), recommendation systems, resource management, and finance, among others.\n",
      "2025-04-04 18:58:41,994 - langchain_aws.llms.bedrock - INFO - Using Bedrock Invoke API to generate response\n",
      "2025-04-04 18:58:44,994 - root - ERROR - Error raised by bedrock service: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many requests, please wait before trying again.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error getting responses: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many requests, please wait before trying again.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Enter your custom prompt here\n",
    "custom_prompt = \"Explain the concept of reinforcement learning in AI\"\n",
    "\n",
    "# Process the custom prompt\n",
    "process_test_prompt(custom_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploitation Mode Test\n",
    "\n",
    "This cell demonstrates how the model works in pure exploitation mode (no exploration)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a temporary model with no exploration\n",
    "exploit_model = QLearningModel(\n",
    "    learning_rate=0.1,\n",
    "    exploration_rate=0.0,  # No exploration, pure exploitation\n",
    "    save_path=\"../results/q_learning_notebook\"\n",
    ")\n",
    "\n",
    "# Load the existing Q-table\n",
    "exploit_model._load_q_table()\n",
    "\n",
    "# Test the model with a new prompt\n",
    "test_prompt = \"What are the advantages of quantum computing over classical computing?\"\n",
    "\n",
    "# Extract features for the state\n",
    "features = exploit_model.extract_features(test_prompt)\n",
    "state_key = exploit_model._get_state_key(features)\n",
    "\n",
    "print(\"Extracted features:\")\n",
    "for key, value in features.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Elaborate the prompt\n",
    "elaborated_test_prompt = elaborator(test_prompt)\n",
    "\n",
    "# Get Q-values for this state\n",
    "if state_key in exploit_model.q_table:\n",
    "    q_values = exploit_model.q_table[state_key]\n",
    "    print(f\"\\nFound Q-values in table: Original={q_values[0]:.4f}, Elaborated={q_values[1]:.4f}\")\n",
    "else:\n",
    "    q_values = [0.0, 0.0]\n",
    "    print(\"\\nNo existing Q-values found for this state. Using default values.\")\n",
    "\n",
    "# Select action based on Q-values (pure exploitation)\n",
    "if q_values[ORIGINAL_PROMPT] > q_values[ELABORATED_PROMPT]:\n",
    "    selected_action = ORIGINAL_PROMPT\n",
    "    selected_prompt = test_prompt\n",
    "    action_name = \"Original\"\n",
    "elif q_values[ELABORATED_PROMPT] > q_values[ORIGINAL_PROMPT]:\n",
    "    selected_action = ELABORATED_PROMPT\n",
    "    selected_prompt = elaborated_test_prompt\n",
    "    action_name = \"Elaborated\"\n",
    "else:\n",
    "    # If Q-values are equal, default to elaborated\n",
    "    selected_action = ELABORATED_PROMPT\n",
    "    selected_prompt = elaborated_test_prompt\n",
    "    action_name = \"Elaborated (default for equal Q-values)\"\n",
    "\n",
    "print(f\"\\nSelected: {action_name} prompt\")\n",
    "\n",
    "# Display both prompts\n",
    "print(\"\\nOriginal prompt:\")\n",
    "print(test_prompt)\n",
    "\n",
    "print(\"\\nElaborated prompt:\")\n",
    "print(elaborated_test_prompt)\n",
    "\n",
    "# Get response for the selected prompt\n",
    "print(f\"\\nGetting response for the {action_name.lower()} prompt...\")\n",
    "try:\n",
    "    response = test_model.invoke(selected_prompt)\n",
    "    print(\"\\nResponse:\")\n",
    "    print(response.content[:500] + \"...\" if len(response.content) > 500 else response.content)\n",
    "except Exception as e:\n",
    "    print(f\"Error getting response: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "The Q-learning model learns from predefined feedback which prompt type (original or elaborated) works better for different types of queries. This approach with predefined prompts and feedback lets you train the model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
