{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S3 Bucket File Processing with Chroma Vector Database\n",
    "\n",
    "This notebook processes all files from an S3 bucket, extracts their content, and stores them in a Chroma vector database for semantic search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages if not already installed\n",
    "!pip install boto3 langchain langchain_community langchain_openai python-dotenv chromadb Pillow ffmpeg-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Optional, Union\n",
    "from tqdm.notebook import tqdm\n",
    "import boto3\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(\"s3_processor\")\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Configuration\n",
    "S3_BUCKET_NAME = os.getenv(\"S3_BUCKET_NAME\", \"your-bucket-name\")\n",
    "S3_PREFIX = os.getenv(\"S3_PREFIX\", \"\")  # Optional prefix to filter objects\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\", \"\")\n",
    "AWS_ACCESS_KEY_ID = os.getenv(\"AWS_ACCESS_KEY_ID\", \"\")\n",
    "AWS_SECRET_ACCESS_KEY = os.getenv(\"AWS_SECRET_ACCESS_KEY\", \"\")\n",
    "AWS_REGION = os.getenv(\"AWS_REGION\", \"us-east-1\")\n",
    "MAX_FILES = int(os.getenv(\"MAX_FILES\", \"100\"))  # Max files to process\n",
    "CHROMA_DB_DIR = os.getenv(\"CHROMA_DB_DIR\", \"./chroma_db\"